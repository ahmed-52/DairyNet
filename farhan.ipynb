{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4196a177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting anyio==4.11.0 (from -r requirements.txt (line 1))\n",
      "  Using cached anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: appnope==0.1.4 in /Applications/anaconda3/envs/Farhan/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (0.1.4)\n",
      "Collecting argon2-cffi==25.1.0 (from -r requirements.txt (line 3))\n",
      "  Using cached argon2_cffi-25.1.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting argon2-cffi-bindings==25.1.0 (from -r requirements.txt (line 4))\n",
      "  Using cached argon2_cffi_bindings-25.1.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
      "Collecting argon2-cffi-bindings==25.1.0 (from -r requirements.txt (line 4))\n",
      "  Using cached argon2_cffi_bindings-25.1.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
      "Collecting arrow==1.4.0 (from -r requirements.txt (line 5))\n",
      "  Using cached arrow-1.4.0-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting asttokens==3.0.0 (from -r requirements.txt (line 6))\n",
      "  Using cached asttokens-3.0.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting arrow==1.4.0 (from -r requirements.txt (line 5))\n",
      "  Using cached arrow-1.4.0-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting asttokens==3.0.0 (from -r requirements.txt (line 6))\n",
      "  Using cached asttokens-3.0.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting async-lru==2.0.5 (from -r requirements.txt (line 7))\n",
      "  Using cached async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting attrs==25.4.0 (from -r requirements.txt (line 8))\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting async-lru==2.0.5 (from -r requirements.txt (line 7))\n",
      "  Using cached async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting attrs==25.4.0 (from -r requirements.txt (line 8))\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting babel==2.17.0 (from -r requirements.txt (line 9))\n",
      "  Using cached babel-2.17.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting beautifulsoup4==4.14.2 (from -r requirements.txt (line 10))\n",
      "  Using cached beautifulsoup4-4.14.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting babel==2.17.0 (from -r requirements.txt (line 9))\n",
      "  Using cached babel-2.17.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting beautifulsoup4==4.14.2 (from -r requirements.txt (line 10))\n",
      "  Using cached beautifulsoup4-4.14.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting bleach==6.3.0 (from -r requirements.txt (line 11))\n",
      "  Using cached bleach-6.3.0-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting certifi==2025.10.5 (from -r requirements.txt (line 12))\n",
      "  Using cached certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting bleach==6.3.0 (from -r requirements.txt (line 11))\n",
      "  Using cached bleach-6.3.0-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting certifi==2025.10.5 (from -r requirements.txt (line 12))\n",
      "  Using cached certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting cffi==2.0.0 (from -r requirements.txt (line 13))\n",
      "  Using cached cffi-2.0.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.6 kB)\n",
      "Collecting cffi==2.0.0 (from -r requirements.txt (line 13))\n",
      "  Using cached cffi-2.0.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.6 kB)\n",
      "Collecting charset-normalizer==3.4.4 (from -r requirements.txt (line 14))\n",
      "  Using cached charset_normalizer-3.4.4-cp310-cp310-macosx_10_9_universal2.whl.metadata (37 kB)\n",
      "Collecting charset-normalizer==3.4.4 (from -r requirements.txt (line 14))\n",
      "  Using cached charset_normalizer-3.4.4-cp310-cp310-macosx_10_9_universal2.whl.metadata (37 kB)\n",
      "Collecting comm==0.2.3 (from -r requirements.txt (line 15))\n",
      "  Using cached comm-0.2.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting comm==0.2.3 (from -r requirements.txt (line 15))\n",
      "  Using cached comm-0.2.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "\u001b[31mERROR: Ignored the following versions that require a different python version: 1.3.3 Requires-Python >=3.11\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement contourpy==1.3.3 (from versions: 0.0.1, 0.0.2, 0.0.3, 0.0.4, 0.0.5, 1.0.0, 1.0.1, 1.0.2, 1.0.3, 1.0.4, 1.0.5, 1.0.6, 1.0.7, 1.1.0, 1.1.1rc1, 1.1.1, 1.2.0, 1.2.1rc1, 1.2.1, 1.3.0, 1.3.1, 1.3.2)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for contourpy==1.3.3\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Ignored the following versions that require a different python version: 1.3.3 Requires-Python >=3.11\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement contourpy==1.3.3 (from versions: 0.0.1, 0.0.2, 0.0.3, 0.0.4, 0.0.5, 1.0.0, 1.0.1, 1.0.2, 1.0.3, 1.0.4, 1.0.5, 1.0.6, 1.0.7, 1.1.0, 1.1.1rc1, 1.1.1, 1.2.0, 1.2.1rc1, 1.2.1, 1.3.0, 1.3.1, 1.3.2)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for contourpy==1.3.3\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "895a7a50",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'networkx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnx\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m defaultdict\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'networkx'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD ALL DATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"ğŸ“¥ Loading FlavorGraph data...\")\n",
    "\n",
    "edges_df = pd.read_csv(\"https://raw.githubusercontent.com/lamypark/FlavorGraph/master/input/edges_191120.csv\")\n",
    "nodes_df = pd.read_csv(\"https://raw.githubusercontent.com/lamypark/FlavorGraph/master/input/nodes_191120.csv\")\n",
    "\n",
    "print(f\"âœ… Loaded {len(nodes_df)} nodes and {len(edges_df)} edges\")\n",
    "print(f\"\\nEdge types:\")\n",
    "print(edges_df['edge_type'].value_counts())\n",
    "print(f\"\\nNode types (sample):\")\n",
    "print(nodes_df['node_type'].value_counts())\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# UNIVERSAL FLAVOR GRAPH CLASS\n",
    "# ============================================================================\n",
    "\n",
    "class UniversalFlavorGraph:\n",
    "    \"\"\"\n",
    "    Complete food pairing system using chemical compounds and recipe data\n",
    "    Works with ANY ingredient in FlavorGraph\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, edges_df, nodes_df):\n",
    "        self.edges_df = edges_df\n",
    "        self.nodes_df = nodes_df\n",
    "        \n",
    "        # Create mappings\n",
    "        self.node_id_to_name = dict(zip(nodes_df['node_id'], nodes_df['name']))\n",
    "        self.node_name_to_id = {str(v).lower(): k for k, v in self.node_id_to_name.items()}\n",
    "        \n",
    "        # Store node types\n",
    "        self.node_types = dict(zip(nodes_df['node_id'], nodes_df['node_type']))\n",
    "        \n",
    "        # Identify different node types\n",
    "        self.ingredient_ids = set()\n",
    "        self.compound_ids = set()\n",
    "        self.drug_ids = set()\n",
    "        \n",
    "        # Build all graphs\n",
    "        self.build_graphs()\n",
    "        \n",
    "    def build_graphs(self):\n",
    "        \"\"\"Build separate graphs for different relationship types\"\"\"\n",
    "        \n",
    "        print(\"\\nğŸ”¨ Building knowledge graphs...\")\n",
    "        \n",
    "        # 1. Ingredient-Ingredient graph (recipe co-occurrence)\n",
    "        self.ing_graph = nx.Graph()\n",
    "        ing_edges = self.edges_df[self.edges_df['edge_type'] == 'ingr-ingr']\n",
    "        for _, row in ing_edges.iterrows():\n",
    "            self.ing_graph.add_edge(row['id_1'], row['id_2'], \n",
    "                                   weight=row['score'])\n",
    "            self.ingredient_ids.add(row['id_1'])\n",
    "            self.ingredient_ids.add(row['id_2'])\n",
    "        \n",
    "        # 2. Ingredient-Compound bipartite graph\n",
    "        self.compound_graph = nx.Graph()\n",
    "        comp_edges = self.edges_df[self.edges_df['edge_type'] == 'ingr-fcomp']\n",
    "        for _, row in comp_edges.iterrows():\n",
    "            self.compound_graph.add_edge(row['id_1'], row['id_2'], \n",
    "                                        weight=row.get('score', 1.0))\n",
    "            self.ingredient_ids.add(row['id_1'])\n",
    "            self.compound_ids.add(row['id_2'])\n",
    "        \n",
    "        # 3. Ingredient-Drug graph (optional for health benefits)\n",
    "        self.drug_graph = nx.Graph()\n",
    "        drug_edges = self.edges_df[self.edges_df['edge_type'] == 'ingr-dcomp']\n",
    "        for _, row in drug_edges.iterrows():\n",
    "            self.drug_graph.add_edge(row['id_1'], row['id_2'], \n",
    "                                    weight=row.get('score', 1.0))\n",
    "            self.ingredient_ids.add(row['id_1'])\n",
    "            self.drug_ids.add(row['id_2'])\n",
    "        \n",
    "        print(f\"âœ… Built graphs:\")\n",
    "        print(f\"   â€¢ {len(self.ingredient_ids)} food ingredients\")\n",
    "        print(f\"   â€¢ {len(self.compound_ids)} flavor compounds\")\n",
    "        print(f\"   â€¢ {len(self.drug_ids)} drug compounds\")\n",
    "        print(f\"   â€¢ {self.ing_graph.number_of_edges()} ingredient-ingredient edges\")\n",
    "        print(f\"   â€¢ {self.compound_graph.number_of_edges()} ingredient-compound edges\")\n",
    "        print(f\"   â€¢ {self.drug_graph.number_of_edges()} ingredient-drug edges\")\n",
    "    \n",
    "    def search_ingredient(self, query: str) -> List[Dict]:\n",
    "        \"\"\"Search for ingredients by name\"\"\"\n",
    "        query = query.lower()\n",
    "        matches = []\n",
    "        \n",
    "        for node_id in self.ingredient_ids:\n",
    "            name = self.node_id_to_name.get(node_id, '')\n",
    "            if query in str(name).lower():\n",
    "                matches.append({\n",
    "                    'id': node_id,\n",
    "                    'name': name,\n",
    "                    'num_compounds': len(self.get_compounds_for_ingredient(name)),\n",
    "                    'num_recipes': self.ing_graph.degree(node_id) if node_id in self.ing_graph else 0\n",
    "                })\n",
    "        \n",
    "        return sorted(matches, key=lambda x: x['num_compounds'], reverse=True)\n",
    "    \n",
    "    def get_ingredient_id(self, ingredient_name: str) -> Optional[int]:\n",
    "        \"\"\"Get ingredient ID from name (fuzzy match)\"\"\"\n",
    "        ingredient_name = str(ingredient_name).lower()\n",
    "        \n",
    "        # Exact match\n",
    "        if ingredient_name in self.node_name_to_id:\n",
    "            return self.node_name_to_id[ingredient_name]\n",
    "        \n",
    "        # Partial match\n",
    "        for name, nid in self.node_name_to_id.items():\n",
    "            if ingredient_name in name and nid in self.ingredient_ids:\n",
    "                return nid\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def get_compounds_for_ingredient(self, ingredient_name: str) -> List[Dict]:\n",
    "        \"\"\"Get all flavor compounds for an ingredient\"\"\"\n",
    "        ingredient_id = self.get_ingredient_id(ingredient_name)\n",
    "        \n",
    "        if not ingredient_id or ingredient_id not in self.compound_graph:\n",
    "            return []\n",
    "        \n",
    "        compounds = []\n",
    "        for neighbor in self.compound_graph.neighbors(ingredient_id):\n",
    "            if neighbor in self.compound_ids:\n",
    "                compounds.append({\n",
    "                    'id': neighbor,\n",
    "                    'name': self.node_id_to_name.get(neighbor, f\"Compound_{neighbor}\"),\n",
    "                    'weight': self.compound_graph[ingredient_id][neighbor]['weight']\n",
    "                })\n",
    "        \n",
    "        return sorted(compounds, key=lambda x: x['weight'], reverse=True)\n",
    "    \n",
    "    def get_ingredients_with_compound(self, compound_id: int) -> List[Dict]:\n",
    "        \"\"\"Get all ingredients that contain a specific compound\"\"\"\n",
    "        if compound_id not in self.compound_graph:\n",
    "            return []\n",
    "        \n",
    "        ingredients = []\n",
    "        for neighbor in self.compound_graph.neighbors(compound_id):\n",
    "            if neighbor in self.ingredient_ids:\n",
    "                ingredients.append({\n",
    "                    'id': neighbor,\n",
    "                    'name': self.node_id_to_name.get(neighbor, f\"Ingredient_{neighbor}\"),\n",
    "                    'weight': self.compound_graph[neighbor][compound_id]['weight']\n",
    "                })\n",
    "        \n",
    "        return ingredients\n",
    "    \n",
    "    def find_shared_compounds(self, ingredient1: str, ingredient2: str) -> List[Dict]:\n",
    "        \"\"\"Find compounds shared between two ingredients\"\"\"\n",
    "        compounds1 = {c['id']: c for c in self.get_compounds_for_ingredient(ingredient1)}\n",
    "        compounds2 = {c['id']: c for c in self.get_compounds_for_ingredient(ingredient2)}\n",
    "        \n",
    "        shared_ids = set(compounds1.keys()).intersection(set(compounds2.keys()))\n",
    "        \n",
    "        return [\n",
    "            {\n",
    "                'id': cid,\n",
    "                'name': self.node_id_to_name.get(cid, f\"Compound_{cid}\"),\n",
    "                'in_ing1': compounds1[cid]['weight'],\n",
    "                'in_ing2': compounds2[cid]['weight']\n",
    "            }\n",
    "            for cid in shared_ids\n",
    "        ]\n",
    "    \n",
    "    def compound_similarity(self, ingredient1: str, ingredient2: str) -> float:\n",
    "        \"\"\"Calculate Jaccard similarity based on shared compounds\"\"\"\n",
    "        compounds1 = set(c['id'] for c in self.get_compounds_for_ingredient(ingredient1))\n",
    "        compounds2 = set(c['id'] for c in self.get_compounds_for_ingredient(ingredient2))\n",
    "        \n",
    "        if not compounds1 or not compounds2:\n",
    "            return 0.0\n",
    "        \n",
    "        intersection = len(compounds1.intersection(compounds2))\n",
    "        union = len(compounds1.union(compounds2))\n",
    "        \n",
    "        return intersection / union if union > 0 else 0.0\n",
    "    \n",
    "    def recipe_cooccurrence_score(self, ingredient1: str, ingredient2: str) -> float:\n",
    "        \"\"\"Get recipe co-occurrence score\"\"\"\n",
    "        id1 = self.get_ingredient_id(ingredient1)\n",
    "        id2 = self.get_ingredient_id(ingredient2)\n",
    "        \n",
    "        if not id1 or not id2:\n",
    "            return 0.0\n",
    "        \n",
    "        if self.ing_graph.has_edge(id1, id2):\n",
    "            return self.ing_graph[id1][id2]['weight']\n",
    "        \n",
    "        return 0.0\n",
    "    \n",
    "    def recommend_pairings(self, \n",
    "                          base_ingredient: str, \n",
    "                          method: str = 'hybrid',\n",
    "                          top_n: int = 10,\n",
    "                          min_shared_compounds: int = 1,\n",
    "                          category_filter: Optional[List[str]] = None) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Recommend ingredient pairings\n",
    "        \n",
    "        Methods:\n",
    "        - 'chemical': Based purely on chemical compound similarity\n",
    "        - 'recipe': Based purely on recipe co-occurrence\n",
    "        - 'hybrid': Combines both (default)\n",
    "        \"\"\"\n",
    "        \n",
    "        base_id = self.get_ingredient_id(base_ingredient)\n",
    "        if not base_id:\n",
    "            return []\n",
    "        \n",
    "        base_compounds = self.get_compounds_for_ingredient(base_ingredient)\n",
    "        \n",
    "        if not base_compounds and method in ['chemical', 'hybrid']:\n",
    "            print(f\"âš ï¸  No compound data for '{base_ingredient}', falling back to recipe method\")\n",
    "            method = 'recipe'\n",
    "        \n",
    "        candidates = defaultdict(lambda: {\n",
    "            'shared_compounds': [],\n",
    "            'compound_similarity': 0.0,\n",
    "            'recipe_score': 0.0,\n",
    "            'final_score': 0.0\n",
    "        })\n",
    "        \n",
    "        # Method 1: Chemical similarity\n",
    "        if method in ['chemical', 'hybrid']:\n",
    "            for compound in base_compounds:\n",
    "                ingredients_with_compound = self.get_ingredients_with_compound(compound['id'])\n",
    "                \n",
    "                for ing in ingredients_with_compound:\n",
    "                    if ing['id'] != base_id:\n",
    "                        ing_name = ing['name']\n",
    "                        candidates[ing_name]['shared_compounds'].append(compound['name'])\n",
    "        \n",
    "        # Method 2: Recipe co-occurrence\n",
    "        if method in ['recipe', 'hybrid']:\n",
    "            if base_id in self.ing_graph:\n",
    "                for neighbor in self.ing_graph.neighbors(base_id):\n",
    "                    ing_name = self.node_id_to_name.get(neighbor)\n",
    "                    if ing_name:\n",
    "                        candidates[ing_name]['recipe_score'] = self.ing_graph[base_id][neighbor]['weight']\n",
    "        \n",
    "        # Calculate final scores\n",
    "        recommendations = []\n",
    "        \n",
    "        for ing_name, data in candidates.items():\n",
    "            # Filter by minimum shared compounds\n",
    "            if len(data['shared_compounds']) < min_shared_compounds:\n",
    "                continue\n",
    "            \n",
    "            # Calculate compound similarity\n",
    "            if method in ['chemical', 'hybrid']:\n",
    "                data['compound_similarity'] = self.compound_similarity(base_ingredient, ing_name)\n",
    "            \n",
    "            # Combined score\n",
    "            if method == 'chemical':\n",
    "                data['final_score'] = data['compound_similarity']\n",
    "            elif method == 'recipe':\n",
    "                data['final_score'] = data['recipe_score']\n",
    "            else:  # hybrid\n",
    "                data['final_score'] = (0.6 * data['compound_similarity']) + (0.4 * data['recipe_score'])\n",
    "            \n",
    "            recommendations.append({\n",
    "                'ingredient': ing_name,\n",
    "                'compound_similarity': data['compound_similarity'],\n",
    "                'recipe_score': data['recipe_score'],\n",
    "                'final_score': data['final_score'],\n",
    "                'shared_compounds': data['shared_compounds'][:5],\n",
    "                'num_shared_compounds': len(data['shared_compounds'])\n",
    "            })\n",
    "        \n",
    "        # Sort by final score\n",
    "        recommendations.sort(key=lambda x: x['final_score'], reverse=True)\n",
    "        \n",
    "        return recommendations[:top_n]\n",
    "    \n",
    "    def explain_pairing(self, ingredient1: str, ingredient2: str):\n",
    "        \"\"\"Explain why two ingredients pair well\"\"\"\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"ğŸ” Analyzing pairing: {ingredient1.upper()} + {ingredient2.upper()}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Compound similarity\n",
    "        shared = self.find_shared_compounds(ingredient1, ingredient2)\n",
    "        comp_sim = self.compound_similarity(ingredient1, ingredient2)\n",
    "        \n",
    "        print(f\"\\nğŸ“Š Chemical Analysis:\")\n",
    "        print(f\"   Compound similarity: {comp_sim:.3f}\")\n",
    "        print(f\"   Shared compounds: {len(shared)}\")\n",
    "        \n",
    "        if shared:\n",
    "            print(f\"\\nğŸ§ª Top shared flavor compounds:\")\n",
    "            for i, comp in enumerate(shared[:10], 1):\n",
    "                print(f\"   {i}. {comp['name']}\")\n",
    "        \n",
    "        # Recipe co-occurrence\n",
    "        recipe_score = self.recipe_cooccurrence_score(ingredient1, ingredient2)\n",
    "        print(f\"\\nğŸ“– Recipe Analysis:\")\n",
    "        print(f\"   Co-occurrence score: {recipe_score:.3f}\")\n",
    "        \n",
    "        if recipe_score > 0:\n",
    "            print(f\"   âœ… These ingredients ARE used together in recipes\")\n",
    "        else:\n",
    "            print(f\"   âš ï¸  These ingredients are NOT commonly used together\")\n",
    "            print(f\"   ğŸ’¡ This could be a NOVEL pairing opportunity!\")\n",
    "        \n",
    "        # Overall verdict\n",
    "        print(f\"\\nğŸ¯ Verdict:\")\n",
    "        if comp_sim > 0.3 or recipe_score > 0.5:\n",
    "            print(f\"   âœ… STRONG PAIRING - Good chemical and/or recipe support\")\n",
    "        elif comp_sim > 0.1 or recipe_score > 0.2:\n",
    "            print(f\"   âš ï¸  MODERATE PAIRING - Some support, worth experimenting\")\n",
    "        else:\n",
    "            print(f\"   âŒ WEAK PAIRING - Little support, likely incompatible\")\n",
    "        \n",
    "        print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    def get_ingredient_profile(self, ingredient_name: str):\n",
    "        \"\"\"Get complete profile of an ingredient\"\"\"\n",
    "        ing_id = self.get_ingredient_id(ingredient_name)\n",
    "        if not ing_id:\n",
    "            print(f\"âŒ Ingredient '{ingredient_name}' not found\")\n",
    "            return\n",
    "        \n",
    "        compounds = self.get_compounds_for_ingredient(ingredient_name)\n",
    "        \n",
    "        # Recipe connections\n",
    "        recipe_connections = 0\n",
    "        if ing_id in self.ing_graph:\n",
    "            recipe_connections = self.ing_graph.degree(ing_id)\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"ğŸ“‹ Profile: {ingredient_name.upper()}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"   ID: {ing_id}\")\n",
    "        print(f\"   Flavor compounds: {len(compounds)}\")\n",
    "        print(f\"   Recipe connections: {recipe_connections}\")\n",
    "        \n",
    "        if compounds:\n",
    "            print(f\"\\nğŸ§ª Top 10 flavor compounds:\")\n",
    "            for i, comp in enumerate(compounds[:10], 1):\n",
    "                print(f\"   {i}. {comp['name']} (weight: {comp['weight']:.3f})\")\n",
    "        \n",
    "        print(f\"{'='*70}\\n\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# INITIALIZE THE GRAPH\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nğŸš€ Initializing Universal Flavor Graph...\")\n",
    "ufg = UniversalFlavorGraph(edges_df, nodes_df)\n",
    "print(\"âœ… Ready!\\n\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def display_recommendations(recommendations: List[Dict], show_compounds: bool = True):\n",
    "    \"\"\"Pretty print recommendations\"\"\"\n",
    "    \n",
    "    if not recommendations:\n",
    "        print(\"âŒ No recommendations found.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n{'Rank':<6} {'Ingredient':<35} {'Score':<8} {'Chem':<8} {'Recipe':<8} {'Shared':<8}\")\n",
    "    print(\"-\" * 110)\n",
    "    \n",
    "    for i, rec in enumerate(recommendations, 1):\n",
    "        print(f\"{i:<6} {rec['ingredient']:<35} {rec['final_score']:.3f}    \"\n",
    "              f\"{rec['compound_similarity']:.3f}    {rec['recipe_score']:.3f}    \"\n",
    "              f\"{rec['num_shared_compounds']:<8}\")\n",
    "        \n",
    "        if show_compounds and rec['shared_compounds']:\n",
    "            compounds_str = ', '.join(rec['shared_compounds'][:3])\n",
    "            if len(rec['shared_compounds']) > 3:\n",
    "                compounds_str += f\" ... (+{len(rec['shared_compounds'])-3} more)\"\n",
    "            print(f\"       ğŸ§ª {compounds_str}\")\n",
    "            print()\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# EXAMPLE USAGE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"ğŸ¯\"*35)\n",
    "print(\"EXAMPLE 1: Find pairings for CHOCOLATE\")\n",
    "print(\"ğŸ¯\"*35)\n",
    "\n",
    "results = ufg.recommend_pairings(\"chocolate\", method='hybrid', top_n=15)\n",
    "display_recommendations(results)\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"ğŸ¯\"*35)\n",
    "print(\"EXAMPLE 2: Find pairings for TOMATO (chemical only)\")\n",
    "print(\"ğŸ¯\"*35)\n",
    "\n",
    "results = ufg.recommend_pairings(\"tomato\", method='chemical', top_n=15)\n",
    "display_recommendations(results)\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"ğŸ¯\"*35)\n",
    "print(\"EXAMPLE 3: Why do STRAWBERRY and BASIL work?\")\n",
    "print(\"ğŸ¯\"*35)\n",
    "\n",
    "ufg.explain_pairing(\"strawberry\", \"basil\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"ğŸ¯\"*35)\n",
    "print(\"EXAMPLE 4: Search for ingredients\")\n",
    "print(\"ğŸ¯\"*35)\n",
    "\n",
    "print(\"\\nğŸ” Searching for 'beef'...\")\n",
    "results = ufg.search_ingredient(\"beef\")\n",
    "for r in results[:5]:\n",
    "    print(f\"   â€¢ {r['name']} (compounds: {r['num_compounds']}, recipes: {r['num_recipes']})\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"ğŸ¯\"*35)\n",
    "print(\"EXAMPLE 5: Get ingredient profile\")\n",
    "print(\"ğŸ¯\"*35)\n",
    "\n",
    "ufg.get_ingredient_profile(\"vanilla\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"ğŸ¯\"*35)\n",
    "print(\"EXAMPLE 6: Novel pairing discovery\")\n",
    "print(\"ğŸ¯\"*35)\n",
    "\n",
    "print(\"\\nğŸ’¡ Finding ingredients with similar compounds to COFFEE but NOT used in recipes:\")\n",
    "results = ufg.recommend_pairings(\"coffee\", method='chemical', top_n=20)\n",
    "\n",
    "# Filter for novel (low recipe score)\n",
    "novel = [r for r in results if r['recipe_score'] < 0.1]\n",
    "print(f\"\\nFound {len(novel)} potential NOVEL pairings:\")\n",
    "display_recommendations(novel[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0430394c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Farhan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
